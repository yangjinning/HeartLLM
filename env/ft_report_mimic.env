# ================== Training ==================
TRAIN_EPOCHS=1
LEARNING_RATE=0.0001
USE_AMP=false
TASKTYPE=report
BATCH_SIZE=10
DATASET=mimic-iv-ecg
LLM=3b
STAGE=finetune
VERBOSE_STEPS=1
EVAL_STEPS=2

# ================== Paths ==================
TOKENIZER_PATH=./ecg_tokenizer/result_tokenzier/best.pt
LOCAL_LLM_PATH=/data/PyProjects/LLM/Llama-3.2-3B
PRETRAIN_PATH=./results/previous/_mimic-iv-ecg_pretrain/checkpoint/checkpoint_epoch0.pth
ROOT_PATH_ECG=/data/ECG-data/MIMIC-ECG/files
ROOT_PATH_JSON=dataset/ecgqa/mimic-iv-ecg/
ROOT_REPORT_JSON=dataset/report/mimic-iv-ecg
